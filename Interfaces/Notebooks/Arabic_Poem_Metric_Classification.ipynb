{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arabic_Poem_Metric_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d0vjDuxuHl8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f35db585-fb57-4716-fbfb-82524ddb1abe"
      },
      "source": [
        "!pip install pyarabic"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyarabic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/77/da852ee13bce3affc55b746cebc0fdc0fc48628dbc5898ce489112cd6bd1/PyArabic-0.6.6.tar.gz (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 3.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyarabic\n",
            "  Building wheel for pyarabic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyarabic: filename=PyArabic-0.6.6-cp36-none-any.whl size=106210 sha256=ab470d6dda2e12609d4b091f8fec5f8e209f00a504c053c33c2133b75c0b814d\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/b5/2d/668d567e8c2b6f10309dbfaba5bfef6ea0b1c0f9f6fb37078f\n",
            "Successfully built pyarabic\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap4lWHWbDwmy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75fc0ab5-3a48-41a7-8ccb-f9ec5cb2debe"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klf1-MC3DEhi",
        "colab_type": "text"
      },
      "source": [
        "We use a product review dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvOJw5Bg6c5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c94d0d6e-024d-481c-b9d9-7caaae0c5655"
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/zaidalyafeai/ARBML/master/datasets/Poem Meters/baits.zip'\n",
        "!unzip final_baits.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-02 18:52:12--  https://raw.githubusercontent.com/zaidalyafeai/Arabic-Poetry/master/final_baits.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2267882 (2.2M) [application/zip]\n",
            "Saving to: ‘final_baits.zip’\n",
            "\n",
            "\rfinal_baits.zip       0%[                    ]       0  --.-KB/s               \rfinal_baits.zip     100%[===================>]   2.16M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-01-02 18:52:12 (30.7 MB/s) - ‘final_baits.zip’ saved [2267882/2267882]\n",
            "\n",
            "Archive:  final_baits.zip\n",
            "   creating: final_baits/\n",
            "  inflating: final_baits/train.txt   \n",
            "  inflating: final_baits/labels.txt  \n",
            "  inflating: final_baits/test.txt    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwlvjSR-DS15",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23FSFg5t6fc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "a015f2f3-9b9c-46f4-c067-6fc0df3a3dbf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "from random import shuffle\n",
        "from pyarabic import araby\n",
        "from tensorflow.keras.layers import GRU, Embedding, Dense, Input, Dropout, Bidirectional, BatchNormalization, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YuVLvAOkrut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZEFvXv2SqUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('final_baits/labels.txt', 'r') as f:\n",
        "  label2name = f.readlines()\n",
        "  label2name = [name.replace('\\n', '') for name in label2name]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfbnvdT4Cmz0",
        "colab_type": "text"
      },
      "source": [
        "## Read the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKhqB_MfCjEP",
        "colab_type": "text"
      },
      "source": [
        "preprocess a review by removing special characters and long spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7MjMLLn6gtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "def extract_data(path, thresh = 70, on_shatrs = False):\n",
        "  global vocab\n",
        "  \n",
        "  text = \"\"\n",
        "  \n",
        "  X = []\n",
        "  y = []\n",
        "    \n",
        "  t = open(path, 'r').read()\n",
        "  t = araby.strip_tashkeel(t)\n",
        "  \n",
        "  # remove some exteranous chars \n",
        "  execluded = '!()*-ـ.:=o[]«»;؛,،~?؟\\u200f\\ufeffـ'\n",
        "  out = \"\"\n",
        "  \n",
        "  for char in t:\n",
        "    if char not in execluded:\n",
        "      out += char\n",
        "      \n",
        "  text += out\n",
        "  baits = out.split('\\n')\n",
        "  for line in baits:\n",
        "    if len(line) <= 1:\n",
        "      continue\n",
        "    label, bait = line.split(' ', 1)\n",
        "    label = int(label)\n",
        "\n",
        "    bait  = bait.strip()\n",
        "    if on_shatrs:\n",
        "      shatrs = bait.split('#')\n",
        "      for shatr in shatrs:\n",
        "        X.append(shatr.strip())\n",
        "        y.append(label)\n",
        "    else:\n",
        "      X.append(bait.strip())\n",
        "      y.append(label)\n",
        "  \n",
        "  #create the vocab \n",
        "  vocab = sorted(set(' '.join(X)))  \n",
        "  \n",
        "  #shuffle the data \n",
        "  X, y = shuffle(X, y)\n",
        "  return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWwTc-z2fv69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = extract_data(\"final_baits/train.txt\", on_shatrs=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7oXawNaVyEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7f6a6fc5-457d-4c6a-cc54-92ef913c0531"
      },
      "source": [
        "for i in range(5):\n",
        "  print(X[i], ' ', label2name[y[i]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "كلما غاض لنا بحر بدا # خضرم طام كريم المورد   ramal\n",
            "نظمتها درا عليه غصت في # بحر القريض وسرت فيه ملجلجا   kamel\n",
            "وإذا تحاشدت المحامل حوله # قمنا فننشد من غرائب مدحنا   kamel\n",
            "لنا آخذ المرباع قبل ربيعة # فأنى لبكر أن تفاخرنا بكر   taweel\n",
            "قاصد وجهها تزور بني الحا # رث أهل الغناء عند الشروب   khafeef\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syg_fvtnC1AK",
        "colab_type": "text"
      },
      "source": [
        "## Create Sequences\n",
        "Create sequences by using the most repeated 500 words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq0Ber9ICcWb",
        "colab_type": "text"
      },
      "source": [
        "## Create Numpy Arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROef8aerf8ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid , y_train, y_valid = train_test_split(X, y, test_size = 0.15, random_state = 41)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63NiojywQ18F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i+1 for i, u in enumerate(vocab)}\n",
        "\n",
        "def to_sequences(X):\n",
        "  X = [[char2idx[char] for char in line] for line in X]\n",
        "  X = pad_sequences(X, padding='post', value=0, maxlen = 100)\n",
        "  return X\n",
        " \n",
        "X_train = to_sequences(X_train)\n",
        "X_valid = to_sequences(X_valid)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_valid = np.array(y_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uHdRK4cCrGJ",
        "colab_type": "text"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3u3OxEcBfJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Input((100,)))\n",
        "model.add(Embedding(len(char2idx)+1, 256))\n",
        "model.add(Bidirectional(GRU(units = 256, return_sequences=True)))\n",
        "model.add(Bidirectional(GRU(units = 256, return_sequences=True)))\n",
        "model.add(Bidirectional(GRU(units = 256)))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(len(label2name), activation = 'softmax'))\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7imJBjJHxK1-",
        "colab_type": "code",
        "outputId": "f6799e73-921a-494d-ce32-98978152dc89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 256)          9984      \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100, 512)          787968    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100, 512)          1181184   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 512)               1181184   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 14)                1806      \n",
            "=================================================================\n",
            "Total params: 3,227,790\n",
            "Trainable params: 3,227,790\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPyUsGe_u9tw",
        "colab_type": "code",
        "outputId": "db9d154a-028a-4a58-b79e-4639b2494d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model(tf.zeros((10, 100))).shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(10), Dimension(14)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-7U36aDCtQu",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEHRYgLhkozM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_delta=0.0001, min_lr=0.0001)]\n",
        "callbacks += [tf.keras.callbacks.ModelCheckpoint('full_verse.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Ew-5ZyC3Nf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c345907e-9503-422f-f6ee-43494e485b2a"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data= (X_valid, y_valid), epochs = 15, batch_size= 128, shuffle = True, callbacks=callbacks)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40055 samples, validate on 7069 samples\n",
            "Epoch 1/2\n",
            "39936/40055 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9750WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "40055/40055 [==============================] - 284s 7ms/sample - loss: 0.0948 - acc: 0.9751 - val_loss: 0.2681 - val_acc: 0.9345\n",
            "Epoch 2/2\n",
            "39936/40055 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9827WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "40055/40055 [==============================] - 282s 7ms/sample - loss: 0.0672 - acc: 0.9827 - val_loss: 0.2749 - val_acc: 0.9354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f85c60e8438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVnnbxyUgDQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('full_verse.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwZQrxhdDV4r",
        "colab_type": "text"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q-Texz3DQsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(sentence):\n",
        "#   sentence = process_review(sentence)\n",
        "  sentence = araby.strip_tashkeel(sentence)\n",
        "  sequence = [char2idx[char] for char in sentence]\n",
        "  sequence = pad_sequences([sequence], maxlen = X_train.shape[1], padding='post', value=0)\n",
        "\n",
        "  pred = model.predict(sequence)[0]\n",
        "  print(label2name[np.argmax(pred, 0).astype('int')], np.max(pred))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMgcfGkZRLF2",
        "colab_type": "code",
        "outputId": "e464469a-2c3f-4bea-fefb-4cf5c9cbc32a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "classify(\"ما تردون على هذا المحب # دائبا يشكو إليكم في الكتب\")\n",
        "classify(\"ولد الهدى فالكائنات ضياء # وفم الزمان تبسم وسناء\")\n",
        "classify(\" لك يا منازل في القلوب منازل # أقفرت أنت وهن منك أواهل\")\n",
        "classify(\"ومن لم يمت بالسيف مات بغيره # تعددت الأسباب والموت واحد\")\n",
        "classify(\"أنا النبي لا كذب # أنا ابن عبد المطلب\")\n",
        "classify(\"هذه دراهم اقفرت # أم ربور محتها الدهور\")\n",
        "classify(\"هزجنا في بواديكم # فأجزلتم عطايانا\")\n",
        "classify(\"بحر سريع ماله ساحل # مستفعلن مستفعلن فاعلن\")\n",
        "classify(\"مَا مَضَى فَاتَ وَالْمُؤَمَّلُ غَيْبٌ # وَلَكَ السَّاعَةُ الَّتِيْ أَنْتَ فِيْهَا\")\n",
        "classify(\"يا ليلُ الصبّ متى غدهُ # أقيامُ الساعة موعدهُ\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ramal 0.9998889\n",
            "kamel 0.9227781\n",
            "kamel 0.97875893\n",
            "taweel 0.99984443\n",
            "mujtath 0.4425953\n",
            "rajaz 0.90593857\n",
            "hazaj 0.99126935\n",
            "saree 0.9779699\n",
            "khafeef 0.9998227\n",
            "mutadarak 0.99999654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzl3yFAY2IlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('full_verse.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79pAD3FE22lf",
        "colab_type": "code",
        "outputId": "ffa87e3c-a15a-4358-e0ea-97dd9e02977d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "label2meter = {i:name for i, name in enumerate(label2name)}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'saree', 1: 'kamel', 2: 'mutakareb', 3: 'mutadarak', 4: 'munsareh', 5: 'madeed', 6: 'mujtath', 7: 'ramal', 8: 'baseet', 9: 'khafeef', 10: 'taweel', 11: 'wafer', 12: 'hazaj', 13: 'rajaz'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APSz8Fvl04J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xzERYfY02gL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter --quantization_bytes 2 --input_format keras  full_verse.h5 model/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbgVZGuG51jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def create_csv(file, dict):\n",
        "    with open(file, 'w') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for key in dict.keys():\n",
        "            writer.writerow([key,dict[key]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_IuXqQ6536t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_csv(\"char2idx.csv\", char2idx)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}