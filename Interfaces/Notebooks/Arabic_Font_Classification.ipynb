{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arabic-font-classification-final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AQJUJ3DPsPfP",
        "RBVC866usGeU",
        "fB2Y203CssdO",
        "aff5mVAEszF4",
        "cvxob5nEs2Lb",
        "X4I3syHss4kr"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km6tttbmrhYd",
        "colab_type": "text"
      },
      "source": [
        "# Arabic Font Classification\n",
        "Author: Mahmoud Aslan\n",
        "\n",
        "Date: 18-7-2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQJUJ3DPsPfP",
        "colab_type": "text"
      },
      "source": [
        "## Ensure Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heYOP546r0ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "assert tf.__version__ == '2.2.0'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4hD9mgJM_zz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "f0c26fae-fcc5-4d83-deb2-8252a4c69276"
      },
      "source": [
        "!pip install tensorflow-determinism"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-determinism\n",
            "  Downloading https://files.pythonhosted.org/packages/76/56/79d74f25b326d8719753172496abc524980fa67d1d98bb247021376e370a/tensorflow-determinism-0.3.0.tar.gz\n",
            "Building wheels for collected packages: tensorflow-determinism\n",
            "  Building wheel for tensorflow-determinism (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-determinism: filename=tensorflow_determinism-0.3.0-cp36-none-any.whl size=9156 sha256=fa6be7fd992b0393c6035a185d5a3d12fc2de2f6cf2d88a72846ee9fa2cd20c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/c3/18/13959a90d3e0d10182a99866d6ff4d0119e9daed6ce014b54c\n",
            "Successfully built tensorflow-determinism\n",
            "Installing collected packages: tensorflow-determinism\n",
            "Successfully installed tensorflow-determinism-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci2DKA6wNJnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random as rn\n",
        "import os\n",
        "\n",
        "rn.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "rng = tf.random.experimental.Generator.from_seed(1234)\n",
        "\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['PYTHONHASHSEED']=str(0)\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = ''\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBVC866usGeU",
        "colab_type": "text"
      },
      "source": [
        "## Fetch and load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-CGmXEYMkrx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "54fe19ba-f415-4aec-e598-09643592125d"
      },
      "source": [
        "!wget 'https://github.com/mhmoodlan/arabic-font-classification/releases/download/v0.1.0/rufa.tar.gz' && tar -xzf '/content/rufa.tar.gz'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-21 05:58:29--  https://github.com/mhmoodlan/arabic-font-classification/releases/download/v0.1.0/rufa.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/280475345/18288f80-c87d-11ea-95ed-712fd4c4a137?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200721%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200721T055829Z&X-Amz-Expires=300&X-Amz-Signature=9b6277706705425f8acd52ea94a912c72f17c2895dda88aee237c2e9749645fb&X-Amz-SignedHeaders=host&actor_id=0&repo_id=280475345&response-content-disposition=attachment%3B%20filename%3Drufa.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-21 05:58:29--  https://github-production-release-asset-2e65be.s3.amazonaws.com/280475345/18288f80-c87d-11ea-95ed-712fd4c4a137?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200721%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200721T055829Z&X-Amz-Expires=300&X-Amz-Signature=9b6277706705425f8acd52ea94a912c72f17c2895dda88aee237c2e9749645fb&X-Amz-SignedHeaders=host&actor_id=0&repo_id=280475345&response-content-disposition=attachment%3B%20filename%3Drufa.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.99.155\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.99.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121264953 (116M) [application/octet-stream]\n",
            "Saving to: ‘rufa.tar.gz’\n",
            "\n",
            "rufa.tar.gz         100%[===================>] 115.65M  23.8MB/s    in 5.5s    \n",
            "\n",
            "2020-07-21 05:58:35 (21.0 MB/s) - ‘rufa.tar.gz’ saved [121264953/121264953]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBCcAI_PPVo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "8de7ee16-8e2e-444a-bf5f-0b42e1291408"
      },
      "source": [
        "print('# of real Ruqaa images: ', len(os.listdir('/content/rufa/real/ruqaa/')))\n",
        "print('# of real Farsi images: ', len(os.listdir('/content/rufa/real/farsi/')))\n",
        "print('# synthesized Ruqaa: ', len(os.listdir('/content/rufa/synth/ruqaa/')))\n",
        "print('# synthesized Farsi: ', len(os.listdir('/content/rufa/synth/farsi/')))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of real Ruqaa images:  260\n",
            "# of real Farsi images:  256\n",
            "# synthesized Ruqaa:  20000\n",
            "# synthesized Farsi:  20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVi7ghEmO5St",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bebb250c-46a4-44be-ad07-d626853f5e5e"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "synth_dir = Path('/content/rufa/synth')\n",
        "real_dir = Path('/content/rufa/real')\n",
        "\n",
        "CLASS_NAMES = np.array([item.name for item in real_dir.glob('*')])\n",
        "CLASS_NAMES"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ruqaa', 'farsi'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXFInzYpQFrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "synth_paths = tf.data.Dataset.list_files(str(synth_dir / '*/*.jpg'), seed=42)\n",
        "real_paths = tf.data.Dataset.list_files(str(real_dir / '*/*.jpg'), seed=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB2Y203CssdO",
        "colab_type": "text"
      },
      "source": [
        "## Train, val, mismatch, test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbkqcGEzQ-Zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_max_data_size = 2**np.int('32')\n",
        "_test_ratio = '0.2'\n",
        "\n",
        "\n",
        "def test_set_check(item):\n",
        "    id = tf.strings.split(tf.strings.split(item, os.sep)[-1], '.')[0]\n",
        "    hash = tf.strings.to_hash_bucket_fast(id, _max_data_size)\n",
        "    return tf.cast(hash, tf.float64) < float(_test_ratio) * _max_data_size\n",
        "\n",
        "def train_set_check(item):\n",
        "    id = tf.strings.split(tf.strings.split(item, os.sep)[-1], '.')[0]\n",
        "    hash = tf.strings.to_hash_bucket_fast(id, _max_data_size)\n",
        "    return tf.cast(hash, tf.float64) >= float(_test_ratio) * _max_data_size"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyE8Bls6RIQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_paths = synth_paths.filter(train_set_check)\n",
        "val_paths = synth_paths.filter(test_set_check)\n",
        "mismatch_paths = real_paths.filter(test_set_check)\n",
        "test_paths = real_paths.filter(train_set_check)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aff5mVAEszF4",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRFjxM56RXaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 32\n",
        "mapping = {0: 'farsi', 1: 'ruqaa'}\n",
        "\n",
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size, seed=42)\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds\n",
        "\n",
        "def parse_image(data_instance):\n",
        "  parts = tf.strings.split(data_instance, os.sep)\n",
        "  label = tf.cast(tf.argmax(tf.cast(parts[-2] == np.array(list(mapping.values())), dtype=tf.float16)), tf.float16)\n",
        "\n",
        "  image = tf.io.read_file(data_instance)\n",
        "  image = tf.image.decode_jpeg(image, 1)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "  if parts[-3] == 'synth':\n",
        "    noise = rng.normal(shape=tf.shape(image), mean=0.0, stddev=0.015, dtype=tf.float32)\n",
        "    image = tf.add( image, noise)\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "\n",
        "    image = tf.image.adjust_jpeg_quality(image, 90)\n",
        "\n",
        "  return image, label"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmIrVEVKSO3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = train_paths.map(parse_image)\n",
        "val_ds = val_paths.map(parse_image)\n",
        "mismatch_ds = mismatch_paths.map(parse_image)\n",
        "full_train_ds = train_ds.concatenate(val_ds.concatenate(mismatch_ds))\n",
        "test_ds = test_paths.map(parse_image)\n",
        "\n",
        "train_ds = prepare_for_training(train_ds)\n",
        "val_ds = prepare_for_training(val_ds)\n",
        "mismatch_ds = prepare_for_training(mismatch_ds)\n",
        "full_train_ds = prepare_for_training(full_train_ds)\n",
        "test_ds = prepare_for_training(test_ds)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvxob5nEs2Lb",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ7Sbl-SSRUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn(input_shape, output_shape):\n",
        "    num_classes = output_shape[0]\n",
        "    dropout_seed = 708090\n",
        "    kernel_seed = 42\n",
        "  \n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(16, 3, activation='relu', input_shape=input_shape, kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Dropout(0.1, seed=dropout_seed),\n",
        "      tf.keras.layers.Conv2D(32, 5, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Dropout(0.1, seed=dropout_seed),\n",
        "      tf.keras.layers.Conv2D(64, 10, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Dropout(0.1, seed=dropout_seed),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu', kernel_regularizer='l2', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed)),\n",
        "      tf.keras.layers.Dropout(0.2, seed=dropout_seed),\n",
        "      tf.keras.layers.Dense(16, activation='relu', kernel_regularizer='l2', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed)),\n",
        "      tf.keras.layers.Dropout(0.2, seed=dropout_seed),\n",
        "      tf.keras.layers.Dense(num_classes, activation='sigmoid', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=kernel_seed))\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vItUjk8iSy6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 6\n",
        "callbacks = None"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAICHuZ3Sj5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "e9f82c1c-b9ea-4822-a885-2873efa6e629"
      },
      "source": [
        "model = cnn((100, 100, 1), (1,))\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer='Adam', metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 98, 98, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 49, 49, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 49, 49, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 45, 45, 32)        12832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 13, 13, 64)        204864    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 514,977\n",
            "Trainable params: 514,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4I3syHss4kr",
        "colab_type": "text"
      },
      "source": [
        "## Training and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF5F2HBv8HAO",
        "colab_type": "text"
      },
      "source": [
        "#### Load pretrained weights, or..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuTMt62B8Grt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "ba9f546b-1b60-494e-f51d-f10d54aa4507"
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/mhmoodlan/arabic-font-classification/master/codebase/code/font_classifier/weights/FontModel_RuFaDataset_cnn_weights(4).h5' -O weights.h5\n",
        "model.load_weights('/content/weights.h5')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-21 06:10:36--  https://raw.githubusercontent.com/mhmoodlan/arabic-font-classification/master/codebase/code/font_classifier/weights/FontModel_RuFaDataset_cnn_weights(4).h5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2090968 (2.0M) [application/octet-stream]\n",
            "Saving to: ‘weights.h5’\n",
            "\n",
            "\rweights.h5            0%[                    ]       0  --.-KB/s               \rweights.h5          100%[===================>]   1.99M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-07-21 06:10:36 (27.7 MB/s) - ‘weights.h5’ saved [2090968/2090968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JEcGuEx8S2j",
        "colab_type": "text"
      },
      "source": [
        "#### or train from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uup72W8uS5G8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "9e2047aa-dd22-4607-d866-ab706114b0ce"
      },
      "source": [
        "model.fit(\n",
        "  full_train_ds,\n",
        "  epochs=epochs,\n",
        "  callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1004/1004 [==============================] - 124s 123ms/step - loss: 0.3770 - accuracy: 0.8473 - val_loss: 0.0675 - val_accuracy: 0.9943\n",
            "Epoch 2/6\n",
            "1004/1004 [==============================] - 37s 37ms/step - loss: 0.0594 - accuracy: 0.9921 - val_loss: 0.0397 - val_accuracy: 0.9963\n",
            "Epoch 3/6\n",
            "1004/1004 [==============================] - 38s 38ms/step - loss: 0.0427 - accuracy: 0.9948 - val_loss: 0.0238 - val_accuracy: 0.9992\n",
            "Epoch 4/6\n",
            "1004/1004 [==============================] - 37s 37ms/step - loss: 0.0345 - accuracy: 0.9961 - val_loss: 0.0168 - val_accuracy: 0.9982\n",
            "Epoch 5/6\n",
            "1004/1004 [==============================] - 36s 36ms/step - loss: 0.0273 - accuracy: 0.9971 - val_loss: 0.0150 - val_accuracy: 0.9997\n",
            "Epoch 6/6\n",
            "1004/1004 [==============================] - 37s 37ms/step - loss: 0.0272 - accuracy: 0.9975 - val_loss: 0.0434 - val_accuracy: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl_2YcS6_DGo",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIRrUgizTOd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "86e4291c-3c82-4325-d06d-410d87c092c5"
      },
      "source": [
        "test_score = model.evaluate(test_ds)\n",
        "print(f\"Test score: {test_score}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 1s 99ms/step - loss: 0.2316 - accuracy: 0.9712\n",
            "Test score: [0.2316255122423172, 0.971222996711731]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WxxzMFuTtDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert np.allclose(test_score, [.231625, .971222])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGmD5lsC_GjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}